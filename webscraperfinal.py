# -*- coding: utf-8 -*-
"""WebScraperFinal.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13tU8derEG3wSpGIvvK7O1fUlLv3ut68g
"""

!pip install selenium

import pandas as pd

from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup



options = Options()
options.add_argument('--headless')
options.add_argument('--no-sandbox')
options.add_argument('--disable-dev-shm-usage')

driver = webdriver.Chrome(options=options)
driver.get("https://www.buddy4study.com/scholarships")

# Wait for listings to load
WebDriverWait(driver, 15).until(
    EC.presence_of_all_elements_located((By.CLASS_NAME, "Listing_categoriesBox__CiGvQ"))
)

# Now parse with BeautifulSoup
soup = BeautifulSoup(driver.page_source, 'html.parser')
links = soup.find_all("a", class_="Listing_categoriesBox__CiGvQ")

print(f"Found {len(links)} links")
for link in links[:5]:
    print(link.get('href'), link.text.strip())

driver.quit()

# Find all h4 tags with the specific class
scholarships = soup.find_all('h4', class_='Listing_scholarshipName__VLFMj')

# Store texts in an array
names = [s.find('p').text.strip() for s in scholarships if s.find('p')]

names

# Find all divs that contain h4s
deadline_div = soup.find_all('div', class_ = 'Listing_calendarDate__WCgKV')

# Extract h4s inside each div
deadline = []
for div in deadline_div:
    h4 = div.find('h4')
    if h4:
        h4_texts.append(h4.text.strip())
deadline_h4  = h4_texts
deadline_h4

deadline_divs = soup.find_all('div', class_='Listing_calendarDate__WCgKV')

deadline_dates = []
for div in deadline_divs:
    ps = div.find_all('p')
    if len(ps) >= 2:
        deadline_dates.append(ps[1].text.strip())  # the second <p> contains the date

print(deadline_dates)

combined = deadline_h4 + deadline_dates
combined

award_divs = soup.find_all('div', class_='Listing_rightAward__DxMQV')

awards = []
for div in award_divs:
    span = div.find('span')
    if span:
        awards.append(span.text.strip())

print(awards)

eligibilities = []

for div in soup.find_all('div', class_='Listing_rightAward__DxMQV'):
    heading = div.find('h4')
    if heading and 'Eligibility' in heading.text:
        span = div.find('span')
        if span:
            eligibilities.append(span.text.strip())

print(eligibilities)

print(f"Length of names: {len(names)}")
print(f"Length of eligibilities: {len(eligibilities)}")
print(f"Length of awards: {len(awards)}")
print(f"Length of combined (deadlines): {len(combined)}")

names = names[:100]
eligibilities = eligibilities[:100]
awards = awards[:100]
combined = combined[:100]

df = pd.DataFrame({
     'Name' : names,
    'Eligibility': eligibilities,
    'Reward': awards,
    'Deadline': combined
})

df.to_json('scholarships.json', orient='records', indent=4)